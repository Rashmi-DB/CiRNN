{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ab8b105c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x7fc52c69d490>"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "seed = 40\n",
    "os.environ['PYTHONHASHSEED']=str(seed)\n",
    "\n",
    "import random\n",
    "import seaborn as sns\n",
    "import torch\n",
    "import torch.nn as nn \n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt \n",
    "import matplotlib as mpl\n",
    "from matplotlib.pyplot import *\n",
    "style.use('ggplot')\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import time\n",
    "import torch.profiler\n",
    "import torch.autograd.profiler as profiler\n",
    "from scipy import stats as st\n",
    "import sklearn.preprocessing as preprocess\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error, r2_score\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.model_selection import GroupShuffleSplit\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "import torch.optim as optim\n",
    "import optuna\n",
    "\n",
    "\n",
    "\n",
    "random.seed(seed)\n",
    "np.random.seed(seed)\n",
    "torch.manual_seed(seed)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c6be63e",
   "metadata": {},
   "source": [
    "### Context Integrated RNN - CiRNN and CxAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e85c75a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda device\n"
     ]
    }
   ],
   "source": [
    "# Predefine 'm' depending on the number of context features\n",
    "# For attention computation Ref: Effective Approaches to Attention-bsaed Neural Machine Translation, Loung et al. 2015\n",
    "# Attention methods: DOT, GENERAL, CONCAT\n",
    "\n",
    "# Get CPU or GPU device for training\n",
    "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "print(f\"Using {device} device\")\n",
    "\n",
    "class ContextGRU(torch.nn.Module):\n",
    "    \"\"\"\n",
    "     simple GRU cell network \n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim, output_dim, context_dim, fc_dim):\n",
    "        super(ContextGRU, self).__init__()\n",
    "        \n",
    "        self.n_x = input_dim\n",
    "        self.n_h = hidden_dim\n",
    "        self.n_y = output_dim\n",
    "        self.n_z = context_dim  \n",
    "        self.m = 9  #dimension of basis function vector (polynomial features) for 3 context features \n",
    "        self.n_l = fc_dim  #hidden dimension of fully connected layer (attention hidden units)\n",
    "       \n",
    "       \n",
    "\n",
    "        # reset gate components\n",
    "        self.linear_reset_w1 = nn.Linear(self.n_x * self.m, self.n_h, bias=True)\n",
    "        self.linear_reset_r1 = nn.Linear(self.n_h, self.n_h, bias=True)\n",
    "\n",
    "\n",
    "        self.linear_reset_w2 = nn.Linear(self.n_x * self.m, self.n_h, bias=True)\n",
    "        self.linear_reset_r2 = nn.Linear(self.n_h, self.n_h, bias=True)\n",
    "        self.activation_1 = nn.Sigmoid()\n",
    "\n",
    "        # update gate components\n",
    "        self.linear_gate_w3 = nn.Linear(self.n_x * self.m, self.n_h, bias=True)\n",
    "        self.linear_gate_r3 = nn.Linear(self.n_h, self.n_h, bias=True)\n",
    "        self.activation_2 = nn.Sigmoid()\n",
    "\n",
    "        self.activation_3 = nn.Tanh()\n",
    "        \n",
    "        # Attention layer\n",
    "        #self.attn = nn.Linear(self.n_h, self.n_h)\n",
    "        self.attn = nn.Linear(self.n_h * self.m, self.n_h)\n",
    "        self.concat_linear = nn.Linear(self.n_h*2, self.n_h)\n",
    "                \n",
    "        # Fully connected layer with attention units as input\n",
    "        self.fc_layer = nn.Sequential(\n",
    "            nn.Linear(self.n_h, self.n_l),\n",
    "            nn.ReLU(inplace = True),\n",
    "            nn.Dropout(p=0.2)\n",
    "        )\n",
    "        \n",
    "        \n",
    "        #output from FC layer\n",
    "        self.linear_output = nn.Linear(self.n_l, self.n_y, bias=True)\n",
    "        \n",
    "                    \n",
    "                \n",
    "    def reset_gate(self, xg, h):  #xg is the kronecker product of x and  basis function G(z)\n",
    "        x_1 = self.linear_reset_w1(xg)\n",
    "        h_1 = self.linear_reset_r1(h)\n",
    "        # gate update\n",
    "        r = self.activation_1(x_1 + h_1)\n",
    "        return r\n",
    "\n",
    "    def update_gate(self, xg, h):\n",
    "        x_2 = self.linear_reset_w2(xg)\n",
    "        h_2 = self.linear_reset_r2(h)\n",
    "        s = self.activation_2( h_2 + x_2)\n",
    "        return s\n",
    "\n",
    "    \n",
    "    def update_component(self, xg, h, r):\n",
    "        x_3 = self.linear_gate_w3(xg)\n",
    "        h_3 = r * self.linear_gate_r3(h) \n",
    "        h_tilda = self.activation_3(x_3+h_3)\n",
    "        return h_tilda\n",
    "    \n",
    "    def attention(self,h,hg):\n",
    "        h_t = h[:,-1,:] #hidden state at last time step: (batch_size,hidden_dim)\n",
    "        attn_score = self.attn(hg)  #h : (batch_size, seq_len, hidden_dim)\n",
    "        #print(attn_score.shape)\n",
    "        attn_scores = torch.bmm(attn_score,h_t.unsqueeze(2) ) \n",
    "        #print(attn_scores.shape)\n",
    "        attn_weights = F.softmax(attn_scores.squeeze(2), dim=1)\n",
    "        #print(attn_weights.shape)\n",
    "        cxt = torch.bmm(h.transpose(1,2),attn_weights.unsqueeze(2)).squeeze(2)\n",
    "        #print(cxt.shape)\n",
    "        attn_hidden = torch.tanh(self.concat_linear(torch.cat((cxt,h_t),dim=1)))\n",
    "        #print(attn_hidden.shape)\n",
    "        return attn_hidden , attn_weights      \n",
    "        \n",
    "    \n",
    "    def compute_fc_output(self, a):\n",
    "        fc_output = self.fc_layer(a)\n",
    "        return fc_output\n",
    "        \n",
    "        \n",
    "    def compute_output(self,o):\n",
    "        y_pred = self.linear_output(o)\n",
    "        return y_pred\n",
    "\n",
    "\n",
    "    def cell_forward(self, x, h, G):\n",
    "        \n",
    "        \"\"\"\n",
    "        Implements a single forward step of the Context GRU-cell \n",
    "        \n",
    "        Input Arguments:\n",
    "            x (mini-batch): input x at time step t , (n,n_x) : (batch_size, input_dim)\n",
    "            h : hidden state at time step t-1, (n,n_h) : (batch_size, hidden_dim)\n",
    "            G : vector of basis funcitons (m,n)           \n",
    "        \n",
    "        Returns:\n",
    "            h_new: hidden state at time step t, (n,n_h)\n",
    "                    \n",
    "        \"\"\"\n",
    "        \n",
    "        # kronecker product of x and G(zt)\n",
    "        n = x.shape[0]\n",
    "        xg = torch.zeros(n,self.n_x*self.m).to(device)\n",
    "        \n",
    "        for i in range(n):\n",
    "        \n",
    "            xg[i,:] = torch.kron(x[i,:],G[:,i])\n",
    "            \n",
    "         \n",
    "                     \n",
    "        # Equation 1. reset gate vector\n",
    "        r = self.reset_gate(xg, h)\n",
    "\n",
    "        # Equation 2: the update gate - the shared update gate vector z\n",
    "        s = self.update_gate(xg, h)\n",
    "\n",
    "        # Equation 3: The almost output component\n",
    "        h_tilda = self.update_component(xg,h,r)\n",
    "\n",
    "        # Equation 4: the new hidden state\n",
    "        h_new = (1-s) * h_tilda  + s * h\n",
    "\n",
    "        #output\n",
    "\n",
    "        #y_pred = self.compute_output(h)\n",
    "        \n",
    "        #kronecker product of h and G \n",
    "        n = h_new.shape[0]\n",
    "        hg = torch.zeros(n,self.n_h*self.m).to(device)\n",
    "        \n",
    "        for i in range(n):\n",
    "            hg[i,:] = torch.kron(h_new[i,:],G[:,i])\n",
    "        \n",
    "\n",
    "        return h_new, hg\n",
    "    \n",
    "\n",
    "    def forward(self, x, z):\n",
    "                             \n",
    "        \"\"\"\n",
    "        Implement the forward propagation of the recurrent neural network \n",
    "\n",
    "        Input Arguments:\n",
    "        x (mini_batch): primary input for every time-step in mini-batches of shape (n, T, n_x)\n",
    "        z (mini_batch): context input for every time-step in mini-batches of shape (n,T,n_z)\n",
    "               \n",
    "\n",
    "        Returns:\n",
    "            h -- Hidden states for every time-step, numpy array of shape (n, T, n_h)\n",
    "            y_pred -- Predictions for every time-step, numpy array of shape (n, T, n_y), \n",
    "            here T is 1 for Seq to Vec RNN\n",
    "        \"\"\"\n",
    "                             \n",
    "        # Retrieve dimensions from shapes of x \n",
    "        #print(x.shape)\n",
    "        #print(z.shape)\n",
    "        n,T,n_x = x.shape\n",
    "        n_y = self.n_y\n",
    "        n_h = self.n_h\n",
    "        n_z = self.n_z\n",
    "       \n",
    "        \n",
    "                                    \n",
    "        # initialize \"h\" \n",
    "   \n",
    "        h = self.init_hidden(n,T,n_h)\n",
    "        hg = self.init_hidden(n,T,n_h*self.m)\n",
    "        \n",
    "        #y_pred = np.zeros((m,T_x,n_y))\n",
    "        #y_pred is single value for one sample, m=1\n",
    "        \n",
    "        #basis function vector\n",
    "        G = self.apply_basis(z[:,0,:])  #G: size of (n,m)\n",
    "      \n",
    "        #for initial time step the hidden state is 0\n",
    "        h_temp = h.clone()        \n",
    "        h_init = h_temp[:,0,:]        \n",
    "        #h_curr, y_curr = self.cell_forward(x[:,0,:],h_init,torch.t(G))\n",
    "        h_curr, hg_curr = self.cell_forward(x[:,0,:],h_init,torch.t(G))  \n",
    "        \n",
    "        # loop over all time-steps\n",
    "        for t in range(1,T):\n",
    "            \n",
    "            #compute the vector of basis functions\n",
    "\n",
    "            G = self.apply_basis(z[:,t,:])  #G: size of (n,m)\n",
    "\n",
    "            # Update next hidden state\n",
    "            # ignore yt_pred for seq to vector\n",
    "            h[:,t,:]= h_curr\n",
    "            hg[:,t,:]= hg_curr\n",
    "            \n",
    "            h_temp = h.clone()\n",
    "            h_prev = h_temp[:,t,:]  #h_prev: (n,n_h)\n",
    "            h_curr, hg_curr = self.cell_forward(x[:,t,:],h_prev, torch.t(G))\n",
    "             \n",
    "            #y_pred[t,:] = yt_pred\n",
    "           \n",
    "        \n",
    "        #compute the predicted output from the last cell i.e at last time step T\n",
    "        y_pred = torch.zeros(n,1,1,device = 'cuda:0')\n",
    "        \n",
    "                \n",
    "        # Save the last hidden state \n",
    "        h[:,t,:] = h_curr   # t = T-1 , the last time step\n",
    "        hg[:,t,:] = hg_curr\n",
    "        \n",
    "        \n",
    "              \n",
    "        # Push through the attention layer\n",
    "        attn_weights = None\n",
    "        a , attn_weights = self.attention(h, hg)\n",
    "        \n",
    "        \n",
    "        # Push though the linear layer\n",
    "        fc_output = self.compute_fc_output(a)\n",
    "        \n",
    "        \n",
    "        #compute the output\n",
    "        y_pred[:,0,:] = self.compute_output(fc_output)\n",
    "        \n",
    "       \n",
    "        \n",
    "        return h, y_pred, attn_weights\n",
    "    \n",
    "    \n",
    "    def init_hidden(self, n:int,T:int, n_h:int):\n",
    "        #initialise the hidden state\n",
    "        #n : batch-size\n",
    "        #T : Input sequence length\n",
    "        #returns h of size (n,T,n_h) \n",
    "        return torch.zeros(n,T,n_h,device = 'cuda:0')\n",
    "    \n",
    "    \n",
    "    def apply_basis(self,zt):\n",
    "        '''\n",
    "        apply the basis function: polynomial degree 2\n",
    "        [z0, z1, z2, z0z0, z0z1, z0z2....]\n",
    "        input arguments:\n",
    "            zt: context vector (n,n_z) for mini-batch of size n and n_z context dim\n",
    "        Returns:\n",
    "            G : tensor of basis functions, (m,n)\n",
    "            \n",
    "        for 3 context features m = 9\n",
    "        '''\n",
    "                      \n",
    "        #poly = PolynomialFeatures(2, include_bias=False, interaction_only=True)\n",
    "        poly = PolynomialFeatures(2, include_bias=False)\n",
    "        G = torch.tensor(poly.fit_transform(zt.cpu().numpy())).to(device) #fit_transform returns nd array\n",
    "        \n",
    "                           \n",
    "        return G  \n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "999d31f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Optimization:\n",
    "    def __init__(self, model, loss_fn, optimizer):\n",
    "        self.model = model\n",
    "        self.loss_fn = loss_fn\n",
    "        self.optimizer = optimizer\n",
    "        self.train_losses = []\n",
    "        self.val_losses = []\n",
    "        self.weights = []      #used for visualising weights\n",
    "        self.settings = []     #saving settings for visualising weights\n",
    "        self.inputs = []       #saving input for visualising \n",
    "    \n",
    "    def train_step(self, x, y, z):\n",
    "        \n",
    "       # with profiler.record_function(\"TRAIN STEP FUNCTION\"):\n",
    "        # Sets model to train mode\n",
    "        self.model.train()\n",
    "\n",
    "        # Makes predictions\n",
    "        h, yhat, attn_weigths = self.model(x, z)\n",
    "        \n",
    "        \n",
    "        # Computes loss\n",
    "        loss = self.loss_fn(y, yhat)\n",
    "        \n",
    "        #with profiler.record_function(\"LOSS_BACKWARD\"):\n",
    "        # Computes gradients\n",
    "        loss.backward()\n",
    "\n",
    "        # Updates parameters and zeroes gradients\n",
    "        self.optimizer.step()\n",
    "        self.optimizer.zero_grad()\n",
    "\n",
    "        # Returns the loss\n",
    "        \n",
    "        return loss.item()\n",
    "\n",
    "    def train(self, train_loader, val_loader, batch_size, n_epochs=50, np_features=1, nc_features=1):\n",
    "        '''\n",
    "        np_features = # primary input features\n",
    "        nc_features = # context input features\n",
    "        '''\n",
    "        #model_path = f'models/{self.model}_{datetime.now().strftime(\"%Y-%m-%d %H:%M:%S\")}'\n",
    "        times = []\n",
    "        for epoch in range(1, n_epochs + 1):\n",
    "            \n",
    "            start_epoch = time.time()\n",
    "            \n",
    "            batch_losses = []\n",
    "            batch_count = 0\n",
    "            for x_batch, z_batch, y_batch in train_loader:\n",
    "                batch_count += 1\n",
    "                x_batch = x_batch.view([batch_size,-1, np_features]).to(device)\n",
    "                y_batch = y_batch.to(device)\n",
    "                z_batch = z_batch.view([batch_size,-1, nc_features]).to(device)\n",
    "                                \n",
    "                #with profiler.profile(with_stack=True, profile_memory=True) as prof:\n",
    "                loss = self.train_step(x_batch, y_batch, z_batch)\n",
    "                #print(prof.key_averages(group_by_stack_n=5).table(sort_by = 'self_cpu_time_total', row_limit = 5))    \n",
    "                \n",
    "                batch_losses.append(loss)\n",
    "                \n",
    "#             if (epoch % 10 == 0):\n",
    "#                     #if (batch_count % 200 == 0):\n",
    "#                         #save the model weights for each batch for analysis\n",
    "#                         #self.save_model(self.model, batch_count, str(z_batch[-1,:,:].detach().cpu().numpy()))\n",
    "#                 for param_tensor in model.state_dict():\n",
    "#                     if (param_tensor == 'linear_reset_w1.weight'):\n",
    "#                         param_val = model.state_dict()[param_tensor].cpu().numpy().tolist()\n",
    "#                         self.weights.append(param_val)\n",
    "#                         self.settings.append(z_batch[-1,:,:].detach().cpu().numpy().tolist())\n",
    "            #self.model.to(device)   \n",
    "                \n",
    "               \n",
    "            training_loss = np.mean(batch_losses)\n",
    "            self.train_losses.append(training_loss)\n",
    "            \n",
    "            \n",
    "            with torch.no_grad():\n",
    "                batch_val_losses = []\n",
    "                for x_val, z_val, y_val in val_loader:\n",
    "                    x_val = x_val.view([batch_size, -1, np_features]).to(device, non_blocking=True)\n",
    "                    y_val = y_val.to(device)\n",
    "                    z_val = z_val.view([batch_size, -1, nc_features]).to(device,non_blocking=True)\n",
    "                    self.model.eval()\n",
    "\n",
    "                    # with profiler.profile(with_stack=True, profile_memory=True) as prof:\n",
    "                    h,yhat, attn_weights = self.model(x_val, z_val)  \n",
    "                    # print(prof.key_averages(group_by_stack_n=5).table(sort_by = 'self_cpu_time_total', row_limit = 5))\n",
    "                    \n",
    "                    val_loss = self.loss_fn(y_val, yhat).item()\n",
    "                    batch_val_losses.append(val_loss)\n",
    "                validation_loss = np.mean(batch_val_losses)\n",
    "                self.val_losses.append(validation_loss)\n",
    "\n",
    "            if (epoch % 5 == 0):\n",
    "                print(\n",
    "                    f\"[{epoch}/{n_epochs}] Training loss: {training_loss:.4f}\\t Validation loss: {validation_loss:.4f}\"\n",
    "                )\n",
    "                \n",
    "           \n",
    "                \n",
    "            torch.cuda.synchronize()\n",
    "            end_epoch = time.time()\n",
    "            elapsed = end_epoch - start_epoch\n",
    "            times.append(elapsed)\n",
    "        \n",
    "        total_time = sum(times)\n",
    "        avg_time = sum(times)/n_epochs\n",
    "            \n",
    "        print(f\"Average Training time: {avg_time:.4f} s for epochs {n_epochs}\") \n",
    "        \n",
    "        print(f\"Total Training time: {total_time:.4f} s for epochs {n_epochs}\")  \n",
    "        \n",
    "\n",
    "        #torch.save(self.model.state_dict(), model_path)\n",
    "        \n",
    "        return validation_loss  #this will be used by otuna to optimize\n",
    "    \n",
    "    def evaluate(self, test_loader, batch_size=1, np_features=1, nc_features = 1):\n",
    "            with torch.no_grad():\n",
    "                predictions = []\n",
    "                values = []\n",
    "                attn_weights = []\n",
    "                for x_test, z_test, y_test in test_loader:\n",
    "                    \n",
    "                    x_test = x_test.view([batch_size,-1, np_features]).to(device, non_blocking=True)\n",
    "                    y_test = y_test.to(device)\n",
    "                    z_test = z_test.view([batch_size,-1, nc_features]).to(device, non_blocking=True)\n",
    "                    self.model.eval()\n",
    "                    h,yhat, attn_wts = self.model(x_test, z_test)\n",
    "                    predictions.append(yhat.detach().cpu().numpy())\n",
    "                    values.append(y_test.detach().cpu().numpy())  \n",
    "                    attn_weights.append(attn_wts.detach().cpu().numpy())\n",
    "           \n",
    "            return predictions, values, attn_weights\n",
    "\n",
    "    def plot_losses(self):\n",
    "            plt.plot(self.train_losses, label=\"Training loss\")\n",
    "            plt.plot(self.val_losses, label=\"Validation loss\")\n",
    "            plt.legend()\n",
    "            plt.title(\"Losses\")\n",
    "            plt.xlabel(\"Epochs\")\n",
    "            plt.ylabel(\"Loss(MSE)\")\n",
    "            plt.show()\n",
    "            plt.close()\n",
    "            \n",
    "    def save_model(self, model, batch_id, settings_val):\n",
    "        \n",
    "        # path = define this\n",
    "        #save model\n",
    "        file_name = 'FD002_Params.txt'\n",
    "        file_path = os.path.join(path,file_name)\n",
    "        f = open(file_path, 'a')\n",
    "        f.write('Batch'+ str(batch_id)+'\\n')\n",
    "        f.write('-------\\n')\n",
    "        for param_tensor in model.state_dict():\n",
    "            param_val = model.state_dict()[param_tensor].cpu().numpy().tolist()\n",
    "            f.write(param_tensor + \"\\t\" + str(param_val))\n",
    "            f.write('\\n---------------\\n')\n",
    "        f.write('Settings\\n')\n",
    "        f.write(settings_val + '\\n')\n",
    "        f.write('---------------\\n')\n",
    "        f.write('\\n')\n",
    "       \n",
    "        f.close()\n",
    "        \n",
    "        \n",
    "    def visualise_weights(self):\n",
    "        \n",
    "#         col = ['r','b','g']\n",
    "#         nrows = len(self.weights)\n",
    "#         for i in range(nrows):\n",
    "#             wtmatrix = np.array(self.weights[i])\n",
    "#             print(wtmatrix.shape)\n",
    "#             fig = plt.figure()\n",
    "#             print(wtmatrix[0:9, 0:9])\n",
    "#             #plt.imshow(wtmatrix[0:9, 0:9])\n",
    "#             sns.heatmap(wtmatrix[0:10, 0:10])\n",
    "            \n",
    "#         fig = plt.figure()  \n",
    "#         for i in range(nrows):\n",
    "#             wtmatrix = np.array(self.weights[i])\n",
    "#             plt.plot(wtmatrix[0:10],wtmatrix [0:10],color = col[i],marker = '.')\n",
    "\n",
    "        return self.weights, self.settings, self.inputs\n",
    "        \n",
    "            \n",
    "        \n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0528e02b",
   "metadata": {},
   "source": [
    "### Example - Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "aa5510f9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([128, 15, 6]) torch.Size([128, 15, 3]) torch.Size([128, 1, 1])\n"
     ]
    }
   ],
   "source": [
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "batch_size = 128\n",
    "\n",
    "#transform the arrays into torch tensors\n",
    "train_features = torch.Tensor(X_train)  #X_train : num_samples, seq_len, num_dim\n",
    "train_targets = torch.Tensor(Y_train)\n",
    "train_cx_features = torch.Tensor(Z_train)\n",
    "\n",
    "val_features = torch.Tensor(X_val)\n",
    "val_targets = torch.Tensor(Y_val)\n",
    "val_cx_features = torch.Tensor(Z_val)\n",
    "\n",
    "\n",
    "train = TensorDataset(train_features,train_cx_features, train_targets)\n",
    "val = TensorDataset(val_features, val_cx_features,val_targets)\n",
    "\n",
    "\n",
    "train_loader = DataLoader(train, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "val_loader = DataLoader(val, batch_size=batch_size, shuffle=False, drop_last=True)\n",
    "\n",
    "examples = iter(train_loader)\n",
    "samples,context,targets = examples.next()\n",
    "print(samples.shape, context.shape,targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "76c3ad92",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "input_dim = X_train.shape[2]\n",
    "output_dim = Y_train.shape[2]\n",
    "context_dim = Z_train.shape[2]\n",
    "\n",
    "hidden_dim = 15\n",
    "layer_dim = 1\n",
    "batch_size = 128\n",
    "dropout = 0.2\n",
    "n_epochs = 100\n",
    "learning_rate = 0.0007\n",
    "weight_decay = 1e-6\n",
    "\n",
    "#dimensions of fully connected layer\n",
    "fc_dim = 25\n",
    "\n",
    "\n",
    "model = ContextGRU(input_dim, hidden_dim, output_dim, context_dim, fc_dim)\n",
    "\n",
    "model = model.to(device)\n",
    "\n",
    "params_list = model.parameters()\n",
    "\n",
    "loss_fn = nn.MSELoss(reduction=\"mean\")\n",
    "\n",
    "optimizer = optim.Adam(params_list,lr=learning_rate, weight_decay=weight_decay)\n",
    "#optimizer = optim.RMSprop(params_list, lr=learning_rate, alpha=0.99, eps=1e-08, weight_decay=weight_decay)\n",
    "#optimizer = optim.SGD(params_list,lr=learning_rate, weight_decay=weight_decay)\n",
    "opt = Optimization(model=model, loss_fn=loss_fn, optimizer=optimizer)\n",
    "opt.train(train_loader, val_loader, batch_size=batch_size, n_epochs=n_epochs, np_features=input_dim, nc_features=context_dim)\n",
    "opt.plot_losses()\n",
    "#opt.visualise_weights()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21fc8332",
   "metadata": {},
   "source": [
    "### Example - Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c5389658",
   "metadata": {},
   "outputs": [],
   "source": [
    " \n",
    "    \n",
    "test_features = torch.Tensor(X_test)\n",
    "test_targets = torch.Tensor(Y_test)\n",
    "test_cx_features = torch.Tensor(Z_test)\n",
    "\n",
    "test = TensorDataset(test_features,test_cx_features, test_targets)\n",
    "\n",
    "#test_loader = DataLoader(test, batch_size=X_test.shape[0], shuffle=False, drop_last=True)\n",
    "test_loader_one = DataLoader(test, batch_size=1, shuffle=False)\n",
    "\n",
    "\n",
    "predictions, values, attn_weights= opt.evaluate(test_loader_one, batch_size=1, np_features=input_dim, nc_features = context_dim)\n",
    "#flatten the multi-dimension array to 1-D array\n",
    "vals = np.concatenate(values, axis=0).ravel()  \n",
    "preds = np.concatenate(predictions, axis=0).ravel()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c41e7dee",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
